
from cProfile import label
import matplotlib.pyplot as plt
class Ploting:
  def __init__(self,buffer):
    self.buffer = buffer
    self.agent1_loss()
    self.agent1_networks()
    self.agent1_value()
    self.agent1_policy()
    self.agent2_loss()
    self.agent2_networks()
    self.agent2_value()
    self.agent2_policy()
    self.agent1_reward()
    self.agent2_reward()
    #self.agent_returns()
    #self.policy()
  def policy(self):
    plt.plot(self.buffer.es_episodes,self.buffer.agent1_policy,label="agent1")
    plt.plot(self.buffer.es_episodes,self.buffer.agent2_policy,label = "agent2")
    plt.xlabel("episode")
    plt.ylabel("policy")
    plt.savefig("memory/ploting/agent_policy")
    plt.close()
  def agent1_loss(self):
    plt.plot(self.buffer.episodes,self.buffer.agent1_mean_loss)
    plt.xlabel("episodes")
    plt.ylabel("loss")
    plt.title("loss vs episodes")
    plt.savefig("memory/ploting/agent1_loss.png")
    plt.close()
  def agent1_reward(self):
    plt.plot(self.buffer.episodes,self.buffer.agent1_mean_reward)
    plt.xlabel("episodes")
    plt.ylabel("loss")
    plt.title("loss vs reward")
    plt.savefig("memory/ploting/agent1_reward.png")
    plt.close()
  def agent2_reward(self):
    plt.plot(self.buffer.episodes,self.buffer.agent2_mean_reward)
    plt.xlabel("episodes")
    plt.ylabel("loss")
    plt.title("loss vs reward")
    plt.savefig("memory/ploting/agent2_reward.png")
    plt.close()
  def agent1_networks(self):
    plt.plot(self.buffer.episodes,self.buffer.agent1_mean_actor,label = "actor_loss")
    plt.plot(self.buffer.episodes,self.buffer.agent1_mean_critic,label = "Critic_loss")
    plt.plot(self.buffer.episodes,self.buffer.agent1_mean_loss,label = "loss")
    plt.xlabel("episode")
    plt.ylabel("loss")
    plt.title("episode_vs_agent1_loss")
    plt.legend()
    plt.savefig("memory/ploting/agent1_network_loss.png")
    plt.close()
  def agent1_value(self):
    plt.plot(self.buffer.episodes,self.buffer.agent1_mean_value,label = "q_value")
    plt.plot(self.buffer.episodes,self.buffer.agent1_meannvalue,label = "next_q_value")
    plt.xlabel("episode")
    plt.ylabel("value")
    plt.title("episode_vs_value")
    plt.legend()
    plt.savefig("memory/ploting/agent1_values.png")
    plt.close()
  def agent1_policy(self):
    plt.plot(self.buffer.episodes,self.buffer.agent1_meanlog,label = "policy")
    plt.plot(self.buffer.episodes,self.buffer.agent1_nextlog,label = "next_policy")
    plt.xlabel("episode")
    plt.ylabel("policy")
    plt.title("episode_vs_policy")
    plt.legend()
    plt.savefig("memory/ploting/agent1_policy.png")
    plt.close()
  def agent2_loss(self):
    plt.plot(self.buffer.episodes,self.buffer.agent2_mean_loss)
    plt.xlabel("episodes")
    plt.ylabel("loss")
    plt.title("loss vs episodes")
    plt.savefig("memory/ploting/agent2_loss.png")
    plt.close()
  def agent2_networks(self):
    plt.plot(self.buffer.episodes,self.buffer.agent2_mean_actor,label = "actor_loss")
    plt.plot(self.buffer.episodes,self.buffer.agent2_mean_critic,label = "Critic_loss")
    plt.plot(self.buffer.episodes,self.buffer.agent2_mean_loss,label = "loss")
    plt.xlabel("episode")
    plt.ylabel("loss")
    plt.title("episode_vs_agent2_loss")
    plt.legend()
    plt.savefig("memory/ploting/agent2_network_loss.png")
    plt.close()
  def agent2_value(self):
    plt.plot(self.buffer.episodes,self.buffer.agent2_mean_value,label = "q_value")
    plt.plot(self.buffer.episodes,self.buffer.agent2_meannvalue,label = "next_q_value")
    plt.xlabel("episode")
    plt.ylabel("value")
    plt.title("episode_vs_value")
    plt.legend()
    plt.savefig("memory/ploting/agent2_values.png")
    plt.close()
  def agent2_policy(self):
    plt.plot(self.buffer.episodes,self.buffer.agent2_meanlog,label = "policy")
    plt.plot(self.buffer.episodes,self.buffer.agent2_nextlog,label = "next_policy")
    plt.xlabel("episode")
    plt.ylabel("policy")
    plt.title("episode_vs_policy")
    plt.legend()
    plt.savefig("memory/ploting/agent2_policy.png")
    plt.close()
  def agent_returns(self):
    plt.plot(self.buffer.episodes,self.buffer.agent1_meanreturn,label = "agent1_returns")
    plt.plot(self.buffer.episodes,self.buffer.agent2_meanreturn,label = "agent2_returns")
    plt.xlabel("episode")
    plt.ylabel("returns")
    plt.title("episode_vs_returns")
    plt.legend()
    plt.savefig("memory/ploting/agent1_returns.png") 
    plt.close()
  def agent_mgn(self):
    plt.plot(self.buffer.episodes,self.buffer.agent1_mean_mgn,label = "agent1_mgn_loss")
    plt.plot(self.buffer.episodes,self.buffer.agent2_mean_mgn,label = "agent2_mgn_loss")
    plt.xlabel("episode")
    plt.ylabel("loss")
    plt.title("episode_vs_agent_mgn_loss")
    plt.legend()
    plt.savefig("memory/ploting/agent1_mgn_loss.png")
    plt.close()
  def loss(self):
    plt.plot(self.buffer.episodes,self.buffer.mean_loss)
    plt.xlabel("episodes")
    plt.ylabel("loss")
    plt.title("loss vs episodes")
    plt.savefig("memory/ploting/loss_vs_episodes.png")
    plt.close()
